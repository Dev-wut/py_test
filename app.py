#!/usr/bin/env python3
"""
PriceZA Hot Deals Scraper
‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏•‡∏à‡∏≤‡∏Å priceza.com
"""

import requests
from bs4 import BeautifulSoup
import json
import csv
from datetime import datetime
import time
import logging
from urllib.parse import urljoin, urlparse
import os
import re # Import re for regular expressions

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏∏ encoding='utf-8'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('priceza_scraper.log', encoding='utf-8'),
        logging.StreamHandler()
    ],
    encoding='utf-8' 
)

class PriceZAScraper:
    # (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç) ‡πÄ‡∏û‡∏¥‡πà‡∏° argument allowed_merchants ‡∏ï‡∏≠‡∏ô kh·ªüi t·∫°o
    def __init__(self, allowed_merchants=None):
        self.base_url = "https://www.priceza.com"
        self.session = requests.Session()
        
        # (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç) ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if allowed_merchants:
            # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
            self.allowed_merchants = [m.strip().upper() for m in allowed_merchants]
        else:
            self.allowed_merchants = []

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ headers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏π‡∏Å block
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/5.0 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'th-TH,th;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        self.hot_deals = []

    def get_page_content(self, url, max_retries=3):
        """‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö"""
        for attempt in range(max_retries):
            try:
                logging.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å: {url} (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})")
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                return response.text
            except requests.exceptions.RequestException as e:
                logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                    continue
                else:
                    logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {url} ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° {max_retries} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
                    return None

    def parse_product_info(self, product_element):
        """
        ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å element (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏≤‡∏° HTML ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤)
        """
        product_info = {
            'title': '',
            'price': '',
            'original_price': '',
            'discount': '',
            'image_url': '',
            'product_url': '',
            'merchant': '',
            'merchant_image': '',
            'rating': '',
            'reviews_count': ''
        }
        
        try:
            # ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            title_elem = product_element.find('h3', class_='pz-pdb_name')
            if title_elem:
                product_info['title'] = title_elem.get('title', '').replace('‡∏£‡∏≤‡∏Ñ‡∏≤ ', '').strip()

            # ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏î‡∏¥‡∏°: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏•‡∏ö '‡∏ø'
            original_price_elem = product_element.find('del', class_='pz-base-price')
            if original_price_elem:
                product_info['original_price'] = original_price_elem.get_text(strip=True).replace('‡∏ø', '')

            # ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            price_elem = product_element.find('span', class_='pz-pdb-price')
            if price_elem:
                op_tag_to_remove = price_elem.find('del')
                if op_tag_to_remove:
                    op_tag_to_remove.extract() 
                product_info['price'] = price_elem.get_text(strip=True).replace('‡∏ø', '')
            
            # ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î
            discount_elem = product_element.find('div', class_='pz-label--discount')
            if discount_elem:
                product_info['discount'] = discount_elem.get_text(strip=True)
            
            # ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            img_elem = product_element.find('img', class_='pz-pdb_media--img')
            if img_elem:
                img_src = img_elem.get('src') or img_elem.get('data-original')
                if img_src:
                    product_info['image_url'] = urljoin(self.base_url, img_src)
            
            # ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞ ‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ (Merchant)
            link_elem = product_element.find('a', href=True, onmousedown=True)
            if link_elem:
                product_info['product_url'] = urljoin(self.base_url, link_elem['href'])
                
                onmousedown_attr = link_elem.get('onmousedown', '')
                match = re.search(r"addGAInteractionEvent\('MerchantProducts','([^']*)'", onmousedown_attr)
                if match:
                    product_info['merchant'] = match.group(1).strip().upper() # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà

            # ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤
            merchant_img_elem = product_element.find('img', class_='pz-pdb_store--img')
            if merchant_img_elem:
                merchant_img_src = merchant_img_elem.get('src') or merchant_img_elem.get('data-original')
                if merchant_img_src:
                    product_info['merchant_image'] = urljoin(self.base_url, merchant_img_src)
            
            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
            rating_elem = product_element.find('div', class_='pz-rating-score-text')
            if rating_elem:
                product_info['rating'] = rating_elem.get_text(strip=True)
                
                review_match = re.search(r'\((\d+)\)', product_info['rating'])
                if review_match:
                    product_info['reviews_count'] = review_match.group(1)

        except Exception as e:
            logging.warning(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: {e}")
        
        return product_info


    def scrape_hot_deals(self):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å"""
        if self.allowed_merchants:
            logging.info(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏• (‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞: {', '.join(self.allowed_merchants)})")
        else:
            logging.info("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏•...")

        
        html_content = self.get_page_content(self.base_url)
        if not html_content:
            return []
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        hot_deals_container = soup.find('div', class_='pz-pdb-section') or soup.find('div', id='home-specials')
        
        if not hot_deals_container:
            logging.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö container ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á hot deals - ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô...")
            hot_deals_container = soup.find('div', class_=lambda x: x and 'special' in x.lower()) or \
                                  soup.find('div', class_=lambda x: x and 'hot' in x.lower()) or \
                                  soup.find('div', class_=lambda x: x and 'deal' in x.lower())
        
        if hot_deals_container:
            logging.info("‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏• - ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤...")
            
            product_elements = hot_deals_container.find_all('div', class_='pz-pdb-item')
            
            if not product_elements:
                 product_elements = hot_deals_container.find_all(['div', 'article', 'li'], 
                                                                class_=lambda x: x and any(keyword in x.lower() 
                                                                for keyword in ['product', 'item', 'card', 'deal']))
            
            logging.info(f"‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ {len(product_elements)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
            for i, product_elem in enumerate(product_elements, 1):
                product_info = self.parse_product_info(product_elem)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if product_info['title'] and product_info['price']:
                    
                    # (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç) ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï -> ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    if not self.allowed_merchants or product_info['merchant'] in self.allowed_merchants:
                        self.hot_deals.append(product_info)
                        logging.info(f"‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà {i} [{product_info['merchant']}]: {product_info['title'][:50]}...")
                    else:
                        logging.info(f"‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà {i} [{product_info['merchant']}] ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ß‡πâ")
                else:
                    logging.warning(f"‡∏Ç‡πâ‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà {i} ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤)")
                
                time.sleep(0.1)
        
        else:
            logging.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏Æ‡∏≠‡∏ï‡∏î‡∏µ‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")
            
        logging.info(f"‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(self.hot_deals)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return self.hot_deals

    def save_to_json(self, filename=None):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô JSON"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"priceza_hot_deals_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'total_products': len(self.hot_deals),
                    'products': self.hot_deals
                }, f, ensure_ascii=False, indent=2)
            logging.info(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• JSON ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {filename}")
            return filename
        except Exception as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON: {e}")
            return None

    def save_to_csv(self, filename=None):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô CSV"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"priceza_hot_deals_{timestamp}.csv"
        
        if not self.hot_deals:
            logging.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            return None
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
                fieldnames = ['title', 'price', 'original_price', 'discount', 
                              'merchant', 'rating', 'reviews_count', 
                              'image_url', 'product_url', 'merchant_image']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for product in self.hot_deals:
                    writer.writerow(product)
            
            logging.info(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {filename}")
            return filename
        except Exception as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV: {e}")
            return None

    def print_summary(self):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        print(f"\n{'='*50}")
        print(f"‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PriceZA Hot Deals")
        print(f"{'='*50}")
        print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(self.hot_deals)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        print(f"‡πÄ‡∏ß‡∏•‡∏≤: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        if self.hot_deals:
            print(f"\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ 5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å:")
            print("-" * 50)
            for i, product in enumerate(self.hot_deals[:5], 1):
                print(f"{i}. {product['title'][:60]}")
                print(f"   ‡∏£‡∏≤‡∏Ñ‡∏≤: {product['price']}")
                if product['original_price']:
                    print(f"   ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏î‡∏¥‡∏°: {product['original_price']}")
                if product['merchant']:
                    print(f"   ‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤: {product['merchant']}")
                print()

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üîç PriceZA Hot Deals Scraper")
    print("=" * 40)
    
    # (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç) ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    merchant_input = input("‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô LAZADA, SHOPEE) ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ (,) \n‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ ‡πÉ‡∏´‡πâ‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: ")
    
    # ‡πÅ‡∏õ‡∏•‡∏á input ‡πÄ‡∏õ‡πá‡∏ô list
    merchants_to_scrape = [m.strip() for m in merchant_input.split(',') if m.strip()]

    # (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç) ‡∏™‡∏£‡πâ‡∏≤‡∏á scraper object ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤
    scraper = PriceZAScraper(allowed_merchants=merchants_to_scrape)
    
    try:
        hot_deals = scraper.scrape_hot_deals()
        
        if hot_deals:
            scraper.print_summary()
            
            print("\nüíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
            json_file = scraper.save_to_json()
            csv_file = scraper.save_to_csv()
            
            print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
            if json_file:
                print(f"   üìÑ JSON: {json_file}")
            if csv_file:
                print(f"   üìä CSV: {csv_file}")
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

if __name__ == "__main__":
    main()